[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Projects",
    "section": "",
    "text": "This is project 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nEleanor Amidei\n\n\nApr 23, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/project1/index.html",
    "href": "blog/project1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 study published in the American Economic Review, economists Dean Karlan (Yale University) and John List (University of Chicago) conducted a large-scale field experiment to evaluate the impact of different types of fundraising appeals on charitable giving. The experiment was designed to test whether certain behavioral economic principles—specifically, those involving matching and challenge grants—could significantly influence donor behavior.\nThe researchers partnered with a nonprofit organization to send out 50,000 fundraising letters to potential donors. These individuals were randomly assigned to receive one of three types of solicitation letters:\nStandard Letter: This control condition contained a straightforward appeal for donations, with no mention of matching or challenge grants.\nMatching Grant Letter: This version of the letter informed potential donors that their contributions would be matched dollar-for-dollar by a large donor, effectively doubling the impact of each gift. The idea was to invoke a sense of increased efficacy and urgency.\nChallenge Grant Letter: In this version, the letter stated that a large donor had already pledged a significant amount of funding, contingent on the organization’s ability to raise additional funds from other donors. This framed the recipient’s contribution as necessary to “meet the challenge” and unlock previously pledged money.\nEach treatment group was randomized to ensure that differences in response could be causally attributed to the content of the letter. The researchers then tracked various outcomes, such as the likelihood of donating, the amount donated, and donor heterogeneity in response to the different appeals.\nThe key finding was that matching grants significantly increased both the likelihood of donating and the average donation amount, while challenge grants did not perform significantly better than the standard appeal. The results provided empirical support for the effectiveness of matching mechanisms in charitable fundraising and have since influenced both economic theory and practical strategies used by nonprofit organizations.\n\n\n\nimport pandas as pd\nimport numpy as np\n\nkarlan_data = pd.read_stata('karlan_list_2007.dta')\nprint(karlan_data.shape)\nprint(karlan_data.columns)\nprint(karlan_data.isnull().sum())\nprint(karlan_data.describe(include='all'))\n\nprint(karlan_data['treatment'].value_counts(normalize=True)) #treatment proportion\nprint(karlan_data['gave'].value_counts(normalize=True))  #donation rate \nprint(karlan_data['amount'].mean()) \nprint(karlan_data.dtypes)  \n\n#capping preview for notebook\npd.set_option('display.max_columns', 10)\n\nThe history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n(50083, 51)\nIndex(['treatment', 'control', 'ratio', 'ratio2', 'ratio3', 'size', 'size25',\n       'size50', 'size100', 'sizeno', 'ask', 'askd1', 'askd2', 'askd3', 'ask1',\n       'ask2', 'ask3', 'amount', 'gave', 'amountchange', 'hpa', 'ltmedmra',\n       'freq', 'years', 'year5', 'mrm2', 'dormant', 'female', 'couple',\n       'state50one', 'nonlit', 'cases', 'statecnt', 'stateresponse',\n       'stateresponset', 'stateresponsec', 'stateresponsetminc', 'perbush',\n       'close25', 'red0', 'blue0', 'redcty', 'bluecty', 'pwhite', 'pblack',\n       'page18_39', 'ave_hh_sz', 'median_hhincome', 'powner', 'psch_atlstba',\n       'pop_propurban'],\n      dtype='object')\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n           treatment       control    ratio        ratio2        ratio3  \\\ncount   50083.000000  50083.000000    50083  50083.000000  50083.000000   \nunique           NaN           NaN        4           NaN           NaN   \ntop              NaN           NaN  Control           NaN           NaN   \nfreq             NaN           NaN    16687           NaN           NaN   \nmean        0.666813      0.333187      NaN      0.222311      0.222211   \nstd         0.471357      0.471357      NaN      0.415803      0.415736   \nmin         0.000000      0.000000      NaN      0.000000      0.000000   \n25%         0.000000      0.000000      NaN      0.000000      0.000000   \n50%         1.000000      0.000000      NaN      0.000000      0.000000   \n75%         1.000000      1.000000      NaN      0.000000      0.000000   \nmax         1.000000      1.000000      NaN      1.000000      1.000000   \n\n           size        size25        size50       size100        sizeno  ...  \\\ncount     50083  50083.000000  50083.000000  50083.000000  50083.000000  ...   \nunique        5           NaN           NaN           NaN           NaN  ...   \ntop     Control           NaN           NaN           NaN           NaN  ...   \nfreq      16687           NaN           NaN           NaN           NaN  ...   \nmean        NaN      0.166723      0.166623      0.166723      0.166743  ...   \nstd         NaN      0.372732      0.372643      0.372732      0.372750  ...   \nmin         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n25%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n50%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n75%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \nmax         NaN      1.000000      1.000000      1.000000      1.000000  ...   \n\n              redcty       bluecty        pwhite        pblack     page18_39  \\\ncount   49978.000000  49978.000000  48217.000000  48047.000000  48217.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.510245      0.488715      0.819599      0.086710      0.321694   \nstd         0.499900      0.499878      0.168561      0.135868      0.103039   \nmin         0.000000      0.000000      0.009418      0.000000      0.000000   \n25%         0.000000      0.000000      0.755845      0.014729      0.258311   \n50%         1.000000      0.000000      0.872797      0.036554      0.305534   \n75%         1.000000      1.000000      0.938827      0.090882      0.369132   \nmax         1.000000      1.000000      1.000000      0.989622      0.997544   \n\n           ave_hh_sz  median_hhincome        powner  psch_atlstba  \\\ncount   48221.000000     48209.000000  48214.000000  48215.000000   \nunique           NaN              NaN           NaN           NaN   \ntop              NaN              NaN           NaN           NaN   \nfreq             NaN              NaN           NaN           NaN   \nmean        2.429012     54815.700533      0.669418      0.391661   \nstd         0.378115     22027.316665      0.193405      0.186599   \nmin         0.000000      5000.000000      0.000000      0.000000   \n25%         2.210000     39181.000000      0.560222      0.235647   \n50%         2.440000     50673.000000      0.712296      0.373744   \n75%         2.660000     66005.000000      0.816798      0.530036   \nmax         5.270000    200001.000000      1.000000      1.000000   \n\n        pop_propurban  \ncount    48217.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.871968  \nstd          0.258654  \nmin          0.000000  \n25%          0.884929  \n50%          1.000000  \n75%          1.000000  \nmax          1.000000  \n\n[11 rows x 51 columns]\ntreatment\n1    0.666813\n0    0.333187\nName: proportion, dtype: float64\ngave\n0    0.979354\n1    0.020646\nName: proportion, dtype: float64\n0.91569394\ntreatment                 int8\ncontrol                   int8\nratio                 category\nratio2                    int8\nratio3                    int8\nsize                  category\nsize25                    int8\nsize50                    int8\nsize100                   int8\nsizeno                    int8\nask                   category\naskd1                     int8\naskd2                     int8\naskd3                     int8\nask1                     int16\nask2                     int16\nask3                     int16\namount                 float32\ngave                      int8\namountchange           float32\nhpa                    float32\nltmedmra                  int8\nfreq                     int16\nyears                  float64\nyear5                     int8\nmrm2                   float64\ndormant                   int8\nfemale                 float64\ncouple                 float64\nstate50one                int8\nnonlit                 float64\ncases                  float64\nstatecnt               float32\nstateresponse          float32\nstateresponset         float32\nstateresponsec         float32\nstateresponsetminc     float32\nperbush                float32\nclose25                float64\nred0                   float64\nblue0                  float64\nredcty                 float64\nbluecty                float64\npwhite                 float32\npblack                 float32\npage18_39              float32\nave_hh_sz              float32\nmedian_hhincome        float64\npowner                 float32\npsch_atlstba           float32\npop_propurban          float32\ndtype: object\n\n\n\n\n\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nWhen doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)._\nI will be testing the following variables to ensure that the treatment and control groups are statistically similar: - mrm2: The number of months since the last donation. - bluecty : If the potential donor lives in a blue county. - freq: The number of prior donations. - female: The gender to the donor.\n\n\n\nfrom scipy import stats\n\n# mrm2\n# groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['mrm2'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['mrm2'].dropna()\n\n\n# Manual calculation of t-statistic\n\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n# Degrees of freedom (Welch's approximation)\ndf = (var1/n1 + var2/n2)**2 / ((var1**2)/((n1**2)*(n1 - 1)) + (var2**2)/((n2**2)*(n2 - 1)))\n\n# Two-tailed p-value\nfrom scipy.stats import t\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\n\n\nprint(\"Manual p-value:\", p_value)\n\nManual t-statistic: 0.1195315522817725\nManual p-value: 0.9048549631450831\n\n\nWith a t-statistic of .12, which is not more extreme than 1.96, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level.\nAdditionally, when we run this t-statistic through a pre-built program, we find the p_value is actually .905, which much higher than the .05 threshold we would need to reject the null hypothesis.\n\nimport pyrsm as rsm \n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"mrm2\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : mrm2\nExplanatory variables: control\nNull hyp.: the effect of x on mrm2 is zero\nAlt. hyp.: the effect of x on mrm2 is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       13.012      0.066  196.815  &lt; .001  ***\ncontrol         -0.014      0.115   -0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.014 df(1, 50080), p.value 0.905\nNr obs: 50,082 (1 obs. dropped)\n\nSum of squares:\n\n                df         SS\nRegression       1          2\nError       50,080  7,309,835\nTotal       50,081  7,309,837\n\nRoot Mean Square Error (RMSE):\n12.081\n\n\nThe positive t-statistic is minimal but indicates the treatment group has a slightly higher number of months since last donation. The p-value is well above 0.05, indicating that this difference is not statistically significant at the 95% confidence level. These are the same results we saw with our manual t-test calculation.\n\n\n\n\n#bluecty - donor county is blue\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['bluecty'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['bluecty'].dropna()\n\n#t-test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\nManual t-statistic: -0.8534850504224853\n\n\nThe t-statistic is -0.85, which is not more extreme than -1.96, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level for the blue county variable.\n\nimport pyrsm as rsm \n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"bluecty\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : bluecty\nExplanatory variables: control\nNull hyp.: the effect of x on bluecty is zero\nAlt. hyp.: the effect of x on bluecty is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.487      0.003  177.974  &lt; .001  ***\ncontrol          0.004      0.005    0.854   0.393     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.729 df(1, 49976), p.value 0.393\nNr obs: 49,978 (105 obs. dropped)\n\nSum of squares:\n\n                df      SS\nRegression       1       0\nError       49,976  12,487\nTotal       49,977  12,488\n\nRoot Mean Square Error (RMSE):\n0.5\n\n\nWe see the same t-statistic here, and the p-value is .396, which is well above the .05 threshold we would need to reject the null hypothesis.\n\n\n\n\n#freq - the number of prior donations\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['freq'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['freq'].dropna()\n\n# manual t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"freq\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nManual t-statistic: -0.11084502380904246\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : freq\nExplanatory variables: control\nNull hyp.: the effect of x on freq is zero\nAlt. hyp.: the effect of x on freq is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        8.035      0.062  128.871  &lt; .001  ***\ncontrol          0.012      0.108    0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\n\nSum of squares:\n\n                df         SS\nRegression       1          1\nError       50,081  6,502,323\nTotal       50,082  6,502,325\n\nRoot Mean Square Error (RMSE):\n11.394\n\n\nThere is no significant difference between the treatment and control groups in terms of the number of prior donations. The t-statistic is very close to zero, and the p-value is well above 0.05, indicating no statistically significant difference at the 95% confidence level. This is consistent across both the t-test and linear regression.\n\n\n\n\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['female'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['female'].dropna()\n\n# manual t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"female\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nManual t-statistic: -1.7535132542519636\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : female\nExplanatory variables: control\nNull hyp.: the effect of x on female is zero\nAlt. hyp.: the effect of x on female is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.275      0.002  110.987  &lt; .001  ***\ncontrol          0.008      0.004    1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972 (1,111 obs. dropped)\n\nSum of squares:\n\n                df     SS\nRegression       1      0\nError       48,970  9,821\nTotal       48,971  9,822\n\nRoot Mean Square Error (RMSE):\n0.448\n\n\nHere the t-statistic generated from the manual test is close to -1.96, but still less extreme at -1.75. This means we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level.\nWhen we run this through a pre-built program, we find the p-value is .08, which is above the .05 threshold but below the .10 threshold.\nThe difference between the percentage of female potential donors is marginally different between the two groups, this difference is not significant at the 95% confidence level. This is true in both the t-test and the linear regression. This variable however does have a significant difference at the 90% confidence level, so it would be worth noting.\n\n\n\n\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\ndonated_treatment = karlan_data[karlan_data['treatment'] == 1][\"gave\"].mean()\nprint(f\"{round(donated_treatment*100,2)}% of treatment group donated\")\ndonated_control = karlan_data[karlan_data['control'] == 1][\"gave\"].mean()\nprint(f\"{round(donated_control*100,2)}% of control group donated\")\n\nplt.figure(figsize=(8, 6))\nplt.bar(['Treatment', 'Control'], [donated_treatment, donated_control], color=['green', 'pink'])\nplt.title('Donation Rates by Group')\nplt.ylabel('Donation Rate')\n\n2.2% of treatment group donated\n1.79% of control group donated\n\n\nText(0, 0.5, 'Donation Rate')\n\n\n\n\n\n\n\n\n\n\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['gave']\ncontrol_group = karlan_data[karlan_data['control'] == 1]['gave']\n\n# t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"gave\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\n#probit regression\nimport statsmodels.api as sm\n\nX = karlan_data['treatment']\nY = karlan_data['gave']\n\nX = sm.add_constant(X)\n\n# probit model\nprobit_model = sm.Probit(Y, X)\nresult = probit_model.fit()\n\nprint(result.summary())\n\n#marginal effects to see if results match from the study\nmfx = result.get_margeff()\nprint(mfx.summary())\n\nManual t-statistic: 3.2094621908279835\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: control\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.022      0.001   28.326  &lt; .001  ***\ncontrol         -0.004      0.001   -3.101   0.002   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 9.618 df(1, 50081), p.value 0.002\nNr obs: 50,083\n\nSum of squares:\n\n                df     SS\nRegression       1      0\nError       50,081  1,012\nTotal       50,082  1,012\n\nRoot Mean Square Error (RMSE):\n0.142\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        19:18:41   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nThere difference between the treatment and control group’s response rate is significant at the 95% confidence level (the t-value is more extreme than 1.96 for a two-tailed test). The treatment group has a higher response rate than the control group, which suggests that the matching grant appeal is effective in increasing the likelihood of making a donation. This finding aligns with the hypothesis that matching grants can enhance donor motivation and engagement.\n\n\n\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n1:1 vs 2:1 match ratio on response rate\n\n# t-test comparing 1:1 match rate and 2:1 match rate\n\n#groups\nmatch_1_1 = karlan_data[karlan_data['ratio'] == 1]['gave']\nmatch_2_1 = karlan_data[karlan_data['ratio2'] == 1]['gave']\n\n# t_test\nn1, n2 = len(match_1_1), len(match_2_1)\nmean1, mean2 = np.mean(match_1_1), np.mean(match_2_1)\nvar1, var2 = np.var(match_1_1, ddof=1), np.var(match_2_1, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\n\nprint(\"Manual t-statistic:\", t_manual)\n# Two-tailed p-value\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\nprint(\"Manual p-value:\", p_value)\n\nManual t-statistic: -0.965048975142932\nManual p-value: 0.33452727037590346\n\n\n2:1 vs 3:1 match ratio on response rate\n\n# t-test comparing 2:1 match rate and 3:1 match rate\n#groups\nmatch_2_1 = karlan_data[karlan_data['ratio2'] == 1]['gave']\nmatch_3_1 = karlan_data[karlan_data['ratio3'] == 1]['gave']\n\n# t_test\nn1, n2 = len(match_2_1), len(match_3_1)\nmean1, mean2 = np.mean(match_2_1), np.mean(match_3_1)\nvar1, var2 = np.var(match_2_1, ddof=1), np.var(match_3_1, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n# Two-tailed p-value\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\nprint(\"Manual p-value:\", p_value)\n\nManual t-statistic: -0.05011581369764474\nManual p-value: 0.9600303977894389\n\n\nThe negative t-statistic indicates that the 2:1 match ratio has a higher mean that the 1:1 ratio, however this difference is not significant at the 95% confidence level. The p-value is .34, which is well above the .05 threshold we would need to reject the null hypothesis.\nThe same applies to the 3:1 match ratio, with a p-value of .96 and a smaller difference between the two groups.\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\n\nkarlan_data[\"ratio1\"] = (karlan_data[\"ratio\"] == 1).astype(int)\n\nX = karlan_data[['ratio1','ratio2','ratio3']]\nY = karlan_data['gave']\n\nX = sm.add_constant(X)\n\n# probit model\nprobit_model = sm.Probit(Y, X)\nresult = probit_model.fit()\n\nprint(result.summary())\n\n#marginal effects to see if results match from the study\nmfx = result.get_margeff()\nprint(mfx.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50079\nMethod:                           MLE   Df Model:                            3\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:                0.001108\nTime:                        19:18:41   Log-Likelihood:                -5029.8\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                   0.01091\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\nratio1         0.0616      0.036      1.726      0.084      -0.008       0.132\nratio2         0.0980      0.035      2.792      0.005       0.029       0.167\nratio3         0.0998      0.035      2.847      0.004       0.031       0.169\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0031      0.002      1.724      0.085      -0.000       0.007\nratio2         0.0049      0.002      2.786      0.005       0.001       0.008\nratio3         0.0050      0.002      2.841      0.004       0.002       0.008\n==============================================================================\n\n\n1:1 ratio shows a coefficient 0.062, meaning the 1:1 ratio is less likely to lead to a donation than the other ratio’s but a match should still increase the probability for a give. The 2:1 ratio has an odds ratio of 0.0980, meaning it is slightly more likely to lead to a donation than the control group. The 3:1 ratio has an odds ratio of 0.0998, meaning it is slightly more likely to lead to a donation than the 2:1 ratio. The p_values indicate that the results for ratio 2 and ratio 3 are statistically significant at the 95% confidence level, while the results for ratio 1 are not.\nCalculating the response rate differences between match ratios:\n\ncalculated directly from the data\n\n\n#means\nmean_1_1 = karlan_data[karlan_data[\"ratio\"] == 1][\"gave\"].mean()\nmean_2_1 = karlan_data[karlan_data[\"ratio\"] == 2][\"gave\"].mean()\nmean_3_1 = karlan_data[karlan_data[\"ratio\"] == 3][\"gave\"].mean()\n\n#differences\ndiff_2_1_vs_1_1 = mean_2_1 - mean_1_1\ndiff_3_1_vs_2_1 = mean_3_1 - mean_2_1\n\nprint(\"2:1 vs 1:1:\", diff_2_1_vs_1_1)\nprint(\"3:1 vs 2:1:\", diff_3_1_vs_2_1)\n\n2:1 vs 1:1: 0.0018842510217149944\n3:1 vs 2:1: 0.00010002398025293902\n\n\n\ncalculated from the differences in coefficients\n\n::: {#12acf9c9 .cell execution_count=14} ``` {.python .cell-code} coef_1_1= result.params[‘ratio1’] coef_2_1= result.params[‘ratio2’] coef_3_1= result.params[‘ratio3’]\n#Difference in effects diff_2_1_vs_1_1= coef_2_1 - coef_1_1 diff_3_1_vs_2_1= coef_3_1 - coef_2_1 print(“Regression-basedeffect of 3:1 vs 2:1 match:”, diff_3_1_vs_2_1) print(“Regression-basedeffect of 2:1 vs 1:1 match:”, diff_2_1_vs_1_1)\nmfx= result.get_margeff() print(mfx.summary()) ```\n::: {.cell-output .cell-output-stdout} Regression-basedeffect of 3:1 vs 2:1 match: 0.0018572014854180002  Regression-basedeffect of 2:1 vs 1:1 match: 0.03634986488779221         Probit Marginal Effects         =====================================  Dep. Variable:                   gave  Method:                          dydx  At:                           overall  ==============================================================================                  dy/dx    std err          z      P&gt;|z|      [0.025      0.975]  ------------------------------------------------------------------------------  ratio1         0.0031      0.002      1.724      0.085      -0.000       0.007  ratio2         0.0049      0.002      2.786      0.005       0.001       0.008  ratio3         0.0050      0.002      2.841      0.004       0.002       0.008  ============================================================================== ::: :::\nBoth raw and model-based results suggest that increasing the match ratio from 1:1 to 2:1 significantly improves donation rates. However, increasing it further to 3:1 provides almost no additional benefit. These findings support the paper’s interpretation that higher match ratios can increase giving, but they also highlight diminishing returns at higher match levels.\nThe p-values for ratio1 are significant at the 90% level but the results for ratio2 and ratio3 are significant at the 95% level..\nBased on the probit model, the 3:1 match leads to a slightly higher (0.0018) latent index score for donation compared to the 2:1 match, holding everything else constant.\n\n\n\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution (amount of donation).\n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"amount\", evar=[\"treatment\"])\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.813      0.067   12.063  &lt; .001  ***\ntreatment        0.154      0.083    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\nIn the regression above, we learn that treatment effect has a slightly significant (not at the 95% confidence level and small) effect on size of donation.\n\nkarlan_donations = karlan_data[karlan_data['gave'] ==1 ]\nreg = rsm.model.regress({\"karlan\": karlan_donations}, rvar=\"amount\", evar=[\"treatment\"])\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       45.540      2.423   18.792  &lt; .001  ***\ntreatment       -1.668      2.872   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\nWhen only including donors, the coefficient of the regression shows us the treatment group donates about $1.67 less than the control group, however this result is not significant at the 95% confidence level. This does not have a causal interpretation because treatment may affect the likelihood of donating, and here we’re looking at the size of the donation conditional on donating.\n\ndonors = karlan_data[karlan_data['gave'] ==1]\n\n# Control\ncontrol_donors = donors[donors['treatment'] == 0]['amount']\nplt.hist(control_donors, bins=30, alpha=0.7, label='Control')\nplt.axvline(control_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title(\"Control Group: Donation Amounts\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\nplt.show()\n\n# Treatment\ntreated_donors = donors[donors['treatment'] == 1]['amount']\nplt.hist(treated_donors, bins=30, alpha=0.7, label='Treatment')\nplt.axvline(treated_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title(\"Treatment Group: Donation Amounts\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. Further suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\nHere, I simulate 10,000 draws from the control and treatment groups, then calculate their differences.\n\n#Simulated Numbers\nnp.random.seed(1)  # For reproducibilit\nsim_control = np.random.choice(control_donors, size=10000, replace=True)\nsim_treated = np.random.choice(treated_donors, size=10000, replace=True)\ndiff=sim_treated-sim_control\n\n#Cumulative Average\ncumulative_avg = np.cumsum(diff) / np.arange(1, len(diff) + 1)\n\n#True Difference in means\nTrue_Diff = treated_donors.mean() - control_donors.mean()\n\nplt.plot(cumulative_avg, label='Cumulative Average')\nplt.axhline(True_Diff, color='red', linestyle='dashed', linewidth=2, label='True Difference')\nplt.title('Cumulative Average of Differences')\nplt.xlabel('Number of Samples')\nplt.ylabel('Cumulative Average')\nplt.legend()\n\n\n\n\n\n\n\n\nBy plotting the cumulative average, we can see it approaches the true difference in means. As we increase the number of samples, the variation stabilizes. The cumulative average converges to the true difference in means. This demonstrates the Law of Large Numbers, as the sample mean approaches the population mean as the sample size increases.\n\n\n\nBelow are 4 histograms with the difference between the control and treatment group in samples sizes of 50,100,150,and 200. We then repeat the sampling 1000x to see the averages\np_control = 0.018 p_treatment = 0.022"
  },
  {
    "objectID": "blog/project1/index.html#section-1-data",
    "href": "blog/project1/index.html#section-1-data",
    "title": "This is project 1",
    "section": "",
    "text": "I cleaned some data\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load dataset\ndf = sns.load_dataset(\"mpg\")\n\n# Drop NA rows just in case\ndf = df.dropna(subset=[\"weight\", \"mpg\"])\n\n# Plot\nsns.scatterplot(data=df, x=\"weight\", y=\"mpg\")\nplt.show()"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "About",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Eleanor Amidei",
    "section": "",
    "text": "I’m an experienced customer operations professional currently pursuing a Master’s in Business Analytics at UC San Diego. After several years working closely with customers and internal teams in high-growth startups, I saw firsthand how valuable data can be in improving processes, identifying opportunities, and supporting smarter decision-making. I returned to school to build a stronger foundation in analytics, focusing on the tools and techniques that turn customer and business data into meaningful and actionable insights. With a blend of practical experience and analytical training, I’m looking to contribute to data-driven teams in customer strategy, revenue operations, or sales analytics."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Eleanor Amidei",
    "section": "",
    "text": "I’m an experienced customer operations professional currently pursuing a Master’s in Business Analytics at UC San Diego. After several years working closely with customers and internal teams in high-growth startups, I saw firsthand how valuable data can be in improving processes, identifying opportunities, and supporting smarter decision-making. I returned to school to build a stronger foundation in analytics, focusing on the tools and techniques that turn customer and business data into meaningful and actionable insights. With a blend of practical experience and analytical training, I’m looking to contribute to data-driven teams in customer strategy, revenue operations, or sales analytics."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Eleanor Amidei",
    "section": "Education",
    "text": "Education\nUniversity of California, San Diego | San Diego, CA\nM.S. in Business Analytics | June 2025\nUniversity of California, Berkeley | Berkeley, CA\nB.A. in Media Studies, Minor in Public Policy | May 2018"
  },
  {
    "objectID": "blog/project2/index.html",
    "href": "blog/project2/index.html",
    "title": "This is project 2",
    "section": "",
    "text": "This is project 2"
  },
  {
    "objectID": "blog/project1/index.html#data-exploration",
    "href": "blog/project1/index.html#data-exploration",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\nkarlan_data = pd.read_stata('karlan_list_2007.dta')\nprint(karlan_data.shape)\nprint(karlan_data.columns)\nprint(karlan_data.isnull().sum())\nprint(karlan_data.describe(include='all'))\n\nprint(karlan_data['treatment'].value_counts(normalize=True)) #treatment proportion\nprint(karlan_data['gave'].value_counts(normalize=True))  #donation rate \nprint(karlan_data['amount'].mean()) \nprint(karlan_data.dtypes)  \n\n#capping preview for notebook\npd.set_option('display.max_columns', 10)\n\nThe history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n(50083, 51)\nIndex(['treatment', 'control', 'ratio', 'ratio2', 'ratio3', 'size', 'size25',\n       'size50', 'size100', 'sizeno', 'ask', 'askd1', 'askd2', 'askd3', 'ask1',\n       'ask2', 'ask3', 'amount', 'gave', 'amountchange', 'hpa', 'ltmedmra',\n       'freq', 'years', 'year5', 'mrm2', 'dormant', 'female', 'couple',\n       'state50one', 'nonlit', 'cases', 'statecnt', 'stateresponse',\n       'stateresponset', 'stateresponsec', 'stateresponsetminc', 'perbush',\n       'close25', 'red0', 'blue0', 'redcty', 'bluecty', 'pwhite', 'pblack',\n       'page18_39', 'ave_hh_sz', 'median_hhincome', 'powner', 'psch_atlstba',\n       'pop_propurban'],\n      dtype='object')\ntreatment                0\ncontrol                  0\nratio                    0\nratio2                   0\nratio3                   0\nsize                     0\nsize25                   0\nsize50                   0\nsize100                  0\nsizeno                   0\nask                      0\naskd1                    0\naskd2                    0\naskd3                    0\nask1                     0\nask2                     0\nask3                     0\namount                   0\ngave                     0\namountchange             0\nhpa                      0\nltmedmra                 0\nfreq                     0\nyears                    1\nyear5                    0\nmrm2                     1\ndormant                  0\nfemale                1111\ncouple                1148\nstate50one               0\nnonlit                 452\ncases                  452\nstatecnt                 0\nstateresponse            0\nstateresponset           0\nstateresponsec           3\nstateresponsetminc       3\nperbush                 35\nclose25                 35\nred0                    35\nblue0                   35\nredcty                 105\nbluecty                105\npwhite                1866\npblack                2036\npage18_39             1866\nave_hh_sz             1862\nmedian_hhincome       1874\npowner                1869\npsch_atlstba          1868\npop_propurban         1866\ndtype: int64\n           treatment       control    ratio        ratio2        ratio3  \\\ncount   50083.000000  50083.000000    50083  50083.000000  50083.000000   \nunique           NaN           NaN        4           NaN           NaN   \ntop              NaN           NaN  Control           NaN           NaN   \nfreq             NaN           NaN    16687           NaN           NaN   \nmean        0.666813      0.333187      NaN      0.222311      0.222211   \nstd         0.471357      0.471357      NaN      0.415803      0.415736   \nmin         0.000000      0.000000      NaN      0.000000      0.000000   \n25%         0.000000      0.000000      NaN      0.000000      0.000000   \n50%         1.000000      0.000000      NaN      0.000000      0.000000   \n75%         1.000000      1.000000      NaN      0.000000      0.000000   \nmax         1.000000      1.000000      NaN      1.000000      1.000000   \n\n           size        size25        size50       size100        sizeno  ...  \\\ncount     50083  50083.000000  50083.000000  50083.000000  50083.000000  ...   \nunique        5           NaN           NaN           NaN           NaN  ...   \ntop     Control           NaN           NaN           NaN           NaN  ...   \nfreq      16687           NaN           NaN           NaN           NaN  ...   \nmean        NaN      0.166723      0.166623      0.166723      0.166743  ...   \nstd         NaN      0.372732      0.372643      0.372732      0.372750  ...   \nmin         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n25%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n50%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n75%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \nmax         NaN      1.000000      1.000000      1.000000      1.000000  ...   \n\n              redcty       bluecty        pwhite        pblack     page18_39  \\\ncount   49978.000000  49978.000000  48217.000000  48047.000000  48217.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.510245      0.488715      0.819599      0.086710      0.321694   \nstd         0.499900      0.499878      0.168561      0.135868      0.103039   \nmin         0.000000      0.000000      0.009418      0.000000      0.000000   \n25%         0.000000      0.000000      0.755845      0.014729      0.258311   \n50%         1.000000      0.000000      0.872797      0.036554      0.305534   \n75%         1.000000      1.000000      0.938827      0.090882      0.369132   \nmax         1.000000      1.000000      1.000000      0.989622      0.997544   \n\n           ave_hh_sz  median_hhincome        powner  psch_atlstba  \\\ncount   48221.000000     48209.000000  48214.000000  48215.000000   \nunique           NaN              NaN           NaN           NaN   \ntop              NaN              NaN           NaN           NaN   \nfreq             NaN              NaN           NaN           NaN   \nmean        2.429012     54815.700533      0.669418      0.391661   \nstd         0.378115     22027.316665      0.193405      0.186599   \nmin         0.000000      5000.000000      0.000000      0.000000   \n25%         2.210000     39181.000000      0.560222      0.235647   \n50%         2.440000     50673.000000      0.712296      0.373744   \n75%         2.660000     66005.000000      0.816798      0.530036   \nmax         5.270000    200001.000000      1.000000      1.000000   \n\n        pop_propurban  \ncount    48217.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.871968  \nstd          0.258654  \nmin          0.000000  \n25%          0.884929  \n50%          1.000000  \n75%          1.000000  \nmax          1.000000  \n\n[11 rows x 51 columns]\ntreatment\n1    0.666813\n0    0.333187\nName: proportion, dtype: float64\ngave\n0    0.979354\n1    0.020646\nName: proportion, dtype: float64\n0.91569394\ntreatment                 int8\ncontrol                   int8\nratio                 category\nratio2                    int8\nratio3                    int8\nsize                  category\nsize25                    int8\nsize50                    int8\nsize100                   int8\nsizeno                    int8\nask                   category\naskd1                     int8\naskd2                     int8\naskd3                     int8\nask1                     int16\nask2                     int16\nask3                     int16\namount                 float32\ngave                      int8\namountchange           float32\nhpa                    float32\nltmedmra                  int8\nfreq                     int16\nyears                  float64\nyear5                     int8\nmrm2                   float64\ndormant                   int8\nfemale                 float64\ncouple                 float64\nstate50one                int8\nnonlit                 float64\ncases                  float64\nstatecnt               float32\nstateresponse          float32\nstateresponset         float32\nstateresponsec         float32\nstateresponsetminc     float32\nperbush                float32\nclose25                float64\nred0                   float64\nblue0                  float64\nredcty                 float64\nbluecty                float64\npwhite                 float32\npblack                 float32\npage18_39              float32\nave_hh_sz              float32\nmedian_hhincome        float64\npowner                 float32\npsch_atlstba           float32\npop_propurban          float32\ndtype: object"
  },
  {
    "objectID": "blog/project1/index.html#balance-test",
    "href": "blog/project1/index.html#balance-test",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\nWhen doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)._\nI will be testing the following variables to ensure that the treatment and control groups are statistically similar: - mrm2: The number of months since the last donation. - bluecty : If the potential donor lives in a blue county. - freq: The number of prior donations. - female: The gender to the donor.\n\n\n\nfrom scipy import stats\n\n# mrm2\n# groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['mrm2'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['mrm2'].dropna()\n\n\n# Manual calculation of t-statistic\n\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n# Degrees of freedom (Welch's approximation)\ndf = (var1/n1 + var2/n2)**2 / ((var1**2)/((n1**2)*(n1 - 1)) + (var2**2)/((n2**2)*(n2 - 1)))\n\n# Two-tailed p-value\nfrom scipy.stats import t\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\n\n\nprint(\"Manual p-value:\", p_value)\n\nManual t-statistic: 0.1195315522817725\nManual p-value: 0.9048549631450831\n\n\nWith a t-statistic of .12, which is not more extreme than 1.96, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level.\nAdditionally, when we run this t-statistic through a pre-built program, we find the p_value is actually .905, which much higher than the .05 threshold we would need to reject the null hypothesis.\n\nimport pyrsm as rsm \n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"mrm2\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : mrm2\nExplanatory variables: control\nNull hyp.: the effect of x on mrm2 is zero\nAlt. hyp.: the effect of x on mrm2 is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       13.012      0.066  196.815  &lt; .001  ***\ncontrol         -0.014      0.115   -0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.014 df(1, 50080), p.value 0.905\nNr obs: 50,082 (1 obs. dropped)\n\nSum of squares:\n\n                df         SS\nRegression       1          2\nError       50,080  7,309,835\nTotal       50,081  7,309,837\n\nRoot Mean Square Error (RMSE):\n12.081\n\n\nThe positive t-statistic is minimal but indicates the treatment group has a slightly higher number of months since last donation. The p-value is well above 0.05, indicating that this difference is not statistically significant at the 95% confidence level. These are the same results we saw with our manual t-test calculation.\n\n\n\n\n#bluecty - donor county is blue\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['bluecty'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['bluecty'].dropna()\n\n#t-test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\nManual t-statistic: -0.8534850504224853\n\n\nThe t-statistic is -0.85, which is not more extreme than -1.96, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level for the blue county variable.\n\nimport pyrsm as rsm \n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"bluecty\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : bluecty\nExplanatory variables: control\nNull hyp.: the effect of x on bluecty is zero\nAlt. hyp.: the effect of x on bluecty is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.487      0.003  177.974  &lt; .001  ***\ncontrol          0.004      0.005    0.854   0.393     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.729 df(1, 49976), p.value 0.393\nNr obs: 49,978 (105 obs. dropped)\n\nSum of squares:\n\n                df      SS\nRegression       1       0\nError       49,976  12,487\nTotal       49,977  12,488\n\nRoot Mean Square Error (RMSE):\n0.5\n\n\nWe see the same t-statistic here, and the p-value is .396, which is well above the .05 threshold we would need to reject the null hypothesis.\n\n\n\n\n#freq - the number of prior donations\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['freq'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['freq'].dropna()\n\n# manual t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"freq\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nManual t-statistic: -0.11084502380904246\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : freq\nExplanatory variables: control\nNull hyp.: the effect of x on freq is zero\nAlt. hyp.: the effect of x on freq is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        8.035      0.062  128.871  &lt; .001  ***\ncontrol          0.012      0.108    0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\n\nSum of squares:\n\n                df         SS\nRegression       1          1\nError       50,081  6,502,323\nTotal       50,082  6,502,325\n\nRoot Mean Square Error (RMSE):\n11.394\n\n\nThere is no significant difference between the treatment and control groups in terms of the number of prior donations. The t-statistic is very close to zero, and the p-value is well above 0.05, indicating no statistically significant difference at the 95% confidence level. This is consistent across both the t-test and linear regression.\n\n\n\n\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['female'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['female'].dropna()\n\n# manual t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"female\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nManual t-statistic: -1.7535132542519636\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : female\nExplanatory variables: control\nNull hyp.: the effect of x on female is zero\nAlt. hyp.: the effect of x on female is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.275      0.002  110.987  &lt; .001  ***\ncontrol          0.008      0.004    1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972 (1,111 obs. dropped)\n\nSum of squares:\n\n                df     SS\nRegression       1      0\nError       48,970  9,821\nTotal       48,971  9,822\n\nRoot Mean Square Error (RMSE):\n0.448\n\n\nHere the t-statistic generated from the manual test is close to -1.96, but still less extreme at -1.75. This means we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level.\nWhen we run this through a pre-built program, we find the p-value is .08, which is above the .05 threshold but below the .10 threshold.\nThe difference between the percentage of female potential donors is marginally different between the two groups, this difference is not significant at the 95% confidence level. This is true in both the t-test and the linear regression. This variable however does have a significant difference at the 90% confidence level, so it would be worth noting."
  },
  {
    "objectID": "blog/project1/index.html#charitable-contribution-made",
    "href": "blog/project1/index.html#charitable-contribution-made",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "First, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\ndonated_treatment = karlan_data[karlan_data['treatment'] == 1][\"gave\"].mean()\nprint(f\"{round(donated_treatment*100,2)}% of treatment group donated\")\ndonated_control = karlan_data[karlan_data['control'] == 1][\"gave\"].mean()\nprint(f\"{round(donated_control*100,2)}% of control group donated\")\n\nplt.figure(figsize=(8, 6))\nplt.bar(['Treatment', 'Control'], [donated_treatment, donated_control], color=['green', 'pink'])\nplt.title('Donation Rates by Group')\nplt.ylabel('Donation Rate')\n\n2.2% of treatment group donated\n1.79% of control group donated\n\n\nText(0, 0.5, 'Donation Rate')\n\n\n\n\n\n\n\n\n\n\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['gave']\ncontrol_group = karlan_data[karlan_data['control'] == 1]['gave']\n\n# t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"gave\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\n#probit regression\nimport statsmodels.api as sm\n\nX = karlan_data['treatment']\nY = karlan_data['gave']\n\nX = sm.add_constant(X)\n\n# probit model\nprobit_model = sm.Probit(Y, X)\nresult = probit_model.fit()\n\nprint(result.summary())\n\n#marginal effects to see if results match from the study\nmfx = result.get_margeff()\nprint(mfx.summary())\n\nManual t-statistic: 3.2094621908279835\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: control\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.022      0.001   28.326  &lt; .001  ***\ncontrol         -0.004      0.001   -3.101   0.002   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 9.618 df(1, 50081), p.value 0.002\nNr obs: 50,083\n\nSum of squares:\n\n                df     SS\nRegression       1      0\nError       50,081  1,012\nTotal       50,082  1,012\n\nRoot Mean Square Error (RMSE):\n0.142\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        19:18:41   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nThere difference between the treatment and control group’s response rate is significant at the 95% confidence level (the t-value is more extreme than 1.96 for a two-tailed test). The treatment group has a higher response rate than the control group, which suggests that the matching grant appeal is effective in increasing the likelihood of making a donation. This finding aligns with the hypothesis that matching grants can enhance donor motivation and engagement."
  },
  {
    "objectID": "blog/project1/index.html#differences-between-match-rates",
    "href": "blog/project1/index.html#differences-between-match-rates",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Next, I assess the effectiveness of different sizes of matched donations on the response rate.\n1:1 vs 2:1 match ratio on response rate\n\n# t-test comparing 1:1 match rate and 2:1 match rate\n\n#groups\nmatch_1_1 = karlan_data[karlan_data['ratio'] == 1]['gave']\nmatch_2_1 = karlan_data[karlan_data['ratio2'] == 1]['gave']\n\n# t_test\nn1, n2 = len(match_1_1), len(match_2_1)\nmean1, mean2 = np.mean(match_1_1), np.mean(match_2_1)\nvar1, var2 = np.var(match_1_1, ddof=1), np.var(match_2_1, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\n\nprint(\"Manual t-statistic:\", t_manual)\n# Two-tailed p-value\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\nprint(\"Manual p-value:\", p_value)\n\nManual t-statistic: -0.965048975142932\nManual p-value: 0.33452727037590346\n\n\n2:1 vs 3:1 match ratio on response rate\n\n# t-test comparing 2:1 match rate and 3:1 match rate\n#groups\nmatch_2_1 = karlan_data[karlan_data['ratio2'] == 1]['gave']\nmatch_3_1 = karlan_data[karlan_data['ratio3'] == 1]['gave']\n\n# t_test\nn1, n2 = len(match_2_1), len(match_3_1)\nmean1, mean2 = np.mean(match_2_1), np.mean(match_3_1)\nvar1, var2 = np.var(match_2_1, ddof=1), np.var(match_3_1, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n# Two-tailed p-value\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\nprint(\"Manual p-value:\", p_value)\n\nManual t-statistic: -0.05011581369764474\nManual p-value: 0.9600303977894389\n\n\nThe negative t-statistic indicates that the 2:1 match ratio has a higher mean that the 1:1 ratio, however this difference is not significant at the 95% confidence level. The p-value is .34, which is well above the .05 threshold we would need to reject the null hypothesis.\nThe same applies to the 3:1 match ratio, with a p-value of .96 and a smaller difference between the two groups.\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\n\nkarlan_data[\"ratio1\"] = (karlan_data[\"ratio\"] == 1).astype(int)\n\nX = karlan_data[['ratio1','ratio2','ratio3']]\nY = karlan_data['gave']\n\nX = sm.add_constant(X)\n\n# probit model\nprobit_model = sm.Probit(Y, X)\nresult = probit_model.fit()\n\nprint(result.summary())\n\n#marginal effects to see if results match from the study\nmfx = result.get_margeff()\nprint(mfx.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50079\nMethod:                           MLE   Df Model:                            3\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:                0.001108\nTime:                        19:18:41   Log-Likelihood:                -5029.8\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                   0.01091\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\nratio1         0.0616      0.036      1.726      0.084      -0.008       0.132\nratio2         0.0980      0.035      2.792      0.005       0.029       0.167\nratio3         0.0998      0.035      2.847      0.004       0.031       0.169\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0031      0.002      1.724      0.085      -0.000       0.007\nratio2         0.0049      0.002      2.786      0.005       0.001       0.008\nratio3         0.0050      0.002      2.841      0.004       0.002       0.008\n==============================================================================\n\n\n1:1 ratio shows a coefficient 0.062, meaning the 1:1 ratio is less likely to lead to a donation than the other ratio’s but a match should still increase the probability for a give. The 2:1 ratio has an odds ratio of 0.0980, meaning it is slightly more likely to lead to a donation than the control group. The 3:1 ratio has an odds ratio of 0.0998, meaning it is slightly more likely to lead to a donation than the 2:1 ratio. The p_values indicate that the results for ratio 2 and ratio 3 are statistically significant at the 95% confidence level, while the results for ratio 1 are not.\nCalculating the response rate differences between match ratios:\n\ncalculated directly from the data\n\n\n#means\nmean_1_1 = karlan_data[karlan_data[\"ratio\"] == 1][\"gave\"].mean()\nmean_2_1 = karlan_data[karlan_data[\"ratio\"] == 2][\"gave\"].mean()\nmean_3_1 = karlan_data[karlan_data[\"ratio\"] == 3][\"gave\"].mean()\n\n#differences\ndiff_2_1_vs_1_1 = mean_2_1 - mean_1_1\ndiff_3_1_vs_2_1 = mean_3_1 - mean_2_1\n\nprint(\"2:1 vs 1:1:\", diff_2_1_vs_1_1)\nprint(\"3:1 vs 2:1:\", diff_3_1_vs_2_1)\n\n2:1 vs 1:1: 0.0018842510217149944\n3:1 vs 2:1: 0.00010002398025293902\n\n\n\ncalculated from the differences in coefficients\n\n::: {#12acf9c9 .cell execution_count=14} ``` {.python .cell-code} coef_1_1= result.params[‘ratio1’] coef_2_1= result.params[‘ratio2’] coef_3_1= result.params[‘ratio3’]\n#Difference in effects diff_2_1_vs_1_1= coef_2_1 - coef_1_1 diff_3_1_vs_2_1= coef_3_1 - coef_2_1 print(“Regression-basedeffect of 3:1 vs 2:1 match:”, diff_3_1_vs_2_1) print(“Regression-basedeffect of 2:1 vs 1:1 match:”, diff_2_1_vs_1_1)\nmfx= result.get_margeff() print(mfx.summary()) ```\n::: {.cell-output .cell-output-stdout} Regression-basedeffect of 3:1 vs 2:1 match: 0.0018572014854180002  Regression-basedeffect of 2:1 vs 1:1 match: 0.03634986488779221         Probit Marginal Effects         =====================================  Dep. Variable:                   gave  Method:                          dydx  At:                           overall  ==============================================================================                  dy/dx    std err          z      P&gt;|z|      [0.025      0.975]  ------------------------------------------------------------------------------  ratio1         0.0031      0.002      1.724      0.085      -0.000       0.007  ratio2         0.0049      0.002      2.786      0.005       0.001       0.008  ratio3         0.0050      0.002      2.841      0.004       0.002       0.008  ============================================================================== ::: :::\nBoth raw and model-based results suggest that increasing the match ratio from 1:1 to 2:1 significantly improves donation rates. However, increasing it further to 3:1 provides almost no additional benefit. These findings support the paper’s interpretation that higher match ratios can increase giving, but they also highlight diminishing returns at higher match levels.\nThe p-values for ratio1 are significant at the 90% level but the results for ratio2 and ratio3 are significant at the 95% level..\nBased on the probit model, the 3:1 match leads to a slightly higher (0.0018) latent index score for donation compared to the 2:1 match, holding everything else constant."
  },
  {
    "objectID": "blog/project1/index.html#size-of-charitable-contribution",
    "href": "blog/project1/index.html#size-of-charitable-contribution",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution (amount of donation).\n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"amount\", evar=[\"treatment\"])\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.813      0.067   12.063  &lt; .001  ***\ntreatment        0.154      0.083    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\nIn the regression above, we learn that treatment effect has a slightly significant (not at the 95% confidence level and small) effect on size of donation.\n\nkarlan_donations = karlan_data[karlan_data['gave'] ==1 ]\nreg = rsm.model.regress({\"karlan\": karlan_donations}, rvar=\"amount\", evar=[\"treatment\"])\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       45.540      2.423   18.792  &lt; .001  ***\ntreatment       -1.668      2.872   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\nWhen only including donors, the coefficient of the regression shows us the treatment group donates about $1.67 less than the control group, however this result is not significant at the 95% confidence level. This does not have a causal interpretation because treatment may affect the likelihood of donating, and here we’re looking at the size of the donation conditional on donating.\n\ndonors = karlan_data[karlan_data['gave'] ==1]\n\n# Control\ncontrol_donors = donors[donors['treatment'] == 0]['amount']\nplt.hist(control_donors, bins=30, alpha=0.7, label='Control')\nplt.axvline(control_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title(\"Control Group: Donation Amounts\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\nplt.show()\n\n# Treatment\ntreated_donors = donors[donors['treatment'] == 1]['amount']\nplt.hist(treated_donors, bins=30, alpha=0.7, label='Treatment')\nplt.axvline(treated_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title(\"Treatment Group: Donation Amounts\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "blog/project1/index.html#simulation-experiment",
    "href": "blog/project1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "As a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. Further suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\n\nHere, I simulate 10,000 draws from the control and treatment groups, then calculate their differences.\n\n#Simulated Numbers\nnp.random.seed(1)  # For reproducibilit\nsim_control = np.random.choice(control_donors, size=10000, replace=True)\nsim_treated = np.random.choice(treated_donors, size=10000, replace=True)\ndiff=sim_treated-sim_control\n\n#Cumulative Average\ncumulative_avg = np.cumsum(diff) / np.arange(1, len(diff) + 1)\n\n#True Difference in means\nTrue_Diff = treated_donors.mean() - control_donors.mean()\n\nplt.plot(cumulative_avg, label='Cumulative Average')\nplt.axhline(True_Diff, color='red', linestyle='dashed', linewidth=2, label='True Difference')\nplt.title('Cumulative Average of Differences')\nplt.xlabel('Number of Samples')\nplt.ylabel('Cumulative Average')\nplt.legend()\n\n\n\n\n\n\n\n\nBy plotting the cumulative average, we can see it approaches the true difference in means. As we increase the number of samples, the variation stabilizes. The cumulative average converges to the true difference in means. This demonstrates the Law of Large Numbers, as the sample mean approaches the population mean as the sample size increases.\n\n\n\nBelow are 4 histograms with the difference between the control and treatment group in samples sizes of 50,100,150,and 200. We then repeat the sampling 1000x to see the averages\np_control = 0.018 p_treatment = 0.022"
  },
  {
    "objectID": "blog/project1/Assignment 1 - AB Testing Code.html",
    "href": "blog/project1/Assignment 1 - AB Testing Code.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "In their 2007 study published in the American Economic Review, economists Dean Karlan (Yale University) and John List (University of Chicago) conducted a large-scale field experiment to evaluate the impact of different types of fundraising appeals on charitable giving. The experiment was designed to test whether certain behavioral economic principles—specifically, those involving matching and challenge grants—could significantly influence donor behavior.\nThe researchers partnered with a nonprofit organization to send out 50,000 fundraising letters to potential donors. These individuals were randomly assigned to receive one of three types of solicitation letters:\nStandard Letter: This control condition contained a straightforward appeal for donations, with no mention of matching or challenge grants.\nMatching Grant Letter: This version of the letter informed potential donors that their contributions would be matched dollar-for-dollar by a large donor, effectively doubling the impact of each gift. The idea was to invoke a sense of increased efficacy and urgency.\nChallenge Grant Letter: In this version, the letter stated that a large donor had already pledged a significant amount of funding, contingent on the organization’s ability to raise additional funds from other donors. This framed the recipient’s contribution as necessary to “meet the challenge” and unlock previously pledged money.\nEach treatment group was randomized to ensure that differences in response could be causally attributed to the content of the letter. The researchers then tracked various outcomes, such as the likelihood of donating, the amount donated, and donor heterogeneity in response to the different appeals.\nThe key finding was that matching grants significantly increased both the likelihood of donating and the average donation amount, while challenge grants did not perform significantly better than the standard appeal. The results provided empirical support for the effectiveness of matching mechanisms in charitable fundraising and have since influenced both economic theory and practical strategies used by nonprofit organizations.\nimport pandas as pd\nimport numpy as np\n\nkarlan_data = pd.read_stata('karlan_list_2007.dta')\nkarlan_data.head()\n\n#pd.set_option('display.max_rows', None)\npd.set_option('display.max_rows', 10)\nprint(karlan_data.shape)\nprint(karlan_data.columns)\nprint(karlan_data.isnull().sum())\nprint(karlan_data.describe(include='all'))\n\nprint(karlan_data['treatment'].value_counts(normalize=True)) #treatment proportion\nprint(karlan_data['gave'].value_counts(normalize=True))  #donation rate \nprint(karlan_data['amount'].mean()) \n\npd.set_option('display.max_rows', None) \nprint(karlan_data.dtypes)  \n\n(50083, 51)\nIndex(['treatment', 'control', 'ratio', 'ratio2', 'ratio3', 'size', 'size25',\n       'size50', 'size100', 'sizeno', 'ask', 'askd1', 'askd2', 'askd3', 'ask1',\n       'ask2', 'ask3', 'amount', 'gave', 'amountchange', 'hpa', 'ltmedmra',\n       'freq', 'years', 'year5', 'mrm2', 'dormant', 'female', 'couple',\n       'state50one', 'nonlit', 'cases', 'statecnt', 'stateresponse',\n       'stateresponset', 'stateresponsec', 'stateresponsetminc', 'perbush',\n       'close25', 'red0', 'blue0', 'redcty', 'bluecty', 'pwhite', 'pblack',\n       'page18_39', 'ave_hh_sz', 'median_hhincome', 'powner', 'psch_atlstba',\n       'pop_propurban'],\n      dtype='object')\ntreatment             0\ncontrol               0\nratio                 0\nratio2                0\nratio3                0\n                   ... \nave_hh_sz          1862\nmedian_hhincome    1874\npowner             1869\npsch_atlstba       1868\npop_propurban      1866\nLength: 51, dtype: int64\n           treatment       control    ratio        ratio2        ratio3  \\\ncount   50083.000000  50083.000000    50083  50083.000000  50083.000000   \nunique           NaN           NaN        4           NaN           NaN   \ntop              NaN           NaN  Control           NaN           NaN   \nfreq             NaN           NaN    16687           NaN           NaN   \nmean        0.666813      0.333187      NaN      0.222311      0.222211   \n...              ...           ...      ...           ...           ...   \nmin         0.000000      0.000000      NaN      0.000000      0.000000   \n25%         0.000000      0.000000      NaN      0.000000      0.000000   \n50%         1.000000      0.000000      NaN      0.000000      0.000000   \n75%         1.000000      1.000000      NaN      0.000000      0.000000   \nmax         1.000000      1.000000      NaN      1.000000      1.000000   \n\n           size        size25        size50       size100        sizeno  ...  \\\ncount     50083  50083.000000  50083.000000  50083.000000  50083.000000  ...   \nunique        5           NaN           NaN           NaN           NaN  ...   \ntop     Control           NaN           NaN           NaN           NaN  ...   \nfreq      16687           NaN           NaN           NaN           NaN  ...   \nmean        NaN      0.166723      0.166623      0.166723      0.166743  ...   \n...         ...           ...           ...           ...           ...  ...   \nmin         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n25%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n50%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \n75%         NaN      0.000000      0.000000      0.000000      0.000000  ...   \nmax         NaN      1.000000      1.000000      1.000000      1.000000  ...   \n\n              redcty       bluecty        pwhite        pblack     page18_39  \\\ncount   49978.000000  49978.000000  48217.000000  48047.000000  48217.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean        0.510245      0.488715      0.819599      0.086710      0.321694   \n...              ...           ...           ...           ...           ...   \nmin         0.000000      0.000000      0.009418      0.000000      0.000000   \n25%         0.000000      0.000000      0.755845      0.014729      0.258311   \n50%         1.000000      0.000000      0.872797      0.036554      0.305534   \n75%         1.000000      1.000000      0.938827      0.090882      0.369132   \nmax         1.000000      1.000000      1.000000      0.989622      0.997544   \n\n           ave_hh_sz  median_hhincome        powner  psch_atlstba  \\\ncount   48221.000000     48209.000000  48214.000000  48215.000000   \nunique           NaN              NaN           NaN           NaN   \ntop              NaN              NaN           NaN           NaN   \nfreq             NaN              NaN           NaN           NaN   \nmean        2.429012     54815.700533      0.669418      0.391661   \n...              ...              ...           ...           ...   \nmin         0.000000      5000.000000      0.000000      0.000000   \n25%         2.210000     39181.000000      0.560222      0.235647   \n50%         2.440000     50673.000000      0.712296      0.373744   \n75%         2.660000     66005.000000      0.816798      0.530036   \nmax         5.270000    200001.000000      1.000000      1.000000   \n\n        pop_propurban  \ncount    48217.000000  \nunique            NaN  \ntop               NaN  \nfreq              NaN  \nmean         0.871968  \n...               ...  \nmin          0.000000  \n25%          0.884929  \n50%          1.000000  \n75%          1.000000  \nmax          1.000000  \n\n[11 rows x 51 columns]\ntreatment\n1    0.666813\n0    0.333187\nName: proportion, dtype: float64\ngave\n0    0.979354\n1    0.020646\nName: proportion, dtype: float64\n0.91569394\ntreatment                 int8\ncontrol                   int8\nratio                 category\nratio2                    int8\nratio3                    int8\nsize                  category\nsize25                    int8\nsize50                    int8\nsize100                   int8\nsizeno                    int8\nask                   category\naskd1                     int8\naskd2                     int8\naskd3                     int8\nask1                     int16\nask2                     int16\nask3                     int16\namount                 float32\ngave                      int8\namountchange           float32\nhpa                    float32\nltmedmra                  int8\nfreq                     int16\nyears                  float64\nyear5                     int8\nmrm2                   float64\ndormant                   int8\nfemale                 float64\ncouple                 float64\nstate50one                int8\nnonlit                 float64\ncases                  float64\nstatecnt               float32\nstateresponse          float32\nstateresponset         float32\nstateresponsec         float32\nstateresponsetminc     float32\nperbush                float32\nclose25                float64\nred0                   float64\nblue0                  float64\nredcty                 float64\nbluecty                float64\npwhite                 float32\npblack                 float32\npage18_39              float32\nave_hh_sz              float32\nmedian_hhincome        float64\npowner                 float32\npsch_atlstba           float32\npop_propurban          float32\ndtype: object"
  },
  {
    "objectID": "blog/project1/Assignment 1 - AB Testing Code.html#balance-test",
    "href": "blog/project1/Assignment 1 - AB Testing Code.html#balance-test",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Balance Test",
    "text": "Balance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n_todo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides.\nWhen doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)._\nI will be testing the following variables to ensure that the treatment and control groups are statistically similar: - mrm2: The number of months since the last donation. - bluecty : If the potential donor lives in a blue county. - freq: The number of prior donations. - female: The gender to the donor.\n\nmrm2\n\nimport pandas as pd\nfrom scipy import stats\n\n# mrm2\n# groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['mrm2'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['mrm2'].dropna()\n\n\n# Manual calculation of t-statistic\n\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n# Degrees of freedom (Welch's approximation)\ndf = (var1/n1 + var2/n2)**2 / ((var1**2)/((n1**2)*(n1 - 1)) + (var2**2)/((n2**2)*(n2 - 1)))\n\n# Two-tailed p-value\nfrom scipy.stats import t\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\n\n\nprint(\"Manual p-value:\", p_value)\n\n\nManual t-statistic: 0.1195315522817725\nManual p-value: 0.9048549631450831\n\n\nWith a t-statistic of .12, which is not more extreme than 1.96, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level.\nAdditionally, when we run this t-statistic through a pre-built program, we find the p_value is actually .905, which much higher than the .05 threshold we would need to reject the null hypothesis.\n\nimport pyrsm as rsm \n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"mrm2\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : mrm2\nExplanatory variables: control\nNull hyp.: the effect of x on mrm2 is zero\nAlt. hyp.: the effect of x on mrm2 is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       13.012      0.066  196.815  &lt; .001  ***\ncontrol         -0.014      0.115   -0.119   0.905     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.014 df(1, 50080), p.value 0.905\nNr obs: 50,082 (1 obs. dropped)\n\nSum of squares:\n\n                df         SS\nRegression       1          2\nError       50,080  7,309,835\nTotal       50,081  7,309,837\n\nRoot Mean Square Error (RMSE):\n12.081\n\n\nThe positive t-statistic is minimal but indicates the treatment group has a slightly higher number of months since last donation. The p-value is well above 0.05, indicating that this difference is not statistically significant at the 95% confidence level. These are the same results we saw with our manual t-test calculation.\n\n\nbluectyc\n\n#bluecty - donor county is blue\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['bluecty'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['bluecty'].dropna()\n\n#t-test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\nManual t-statistic: -0.8534850504224853\n\n\nthe t-statistic is -0.85, which is not more extreme than -1.96, we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level for the blue county variable.\n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"bluecty\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : bluecty\nExplanatory variables: control\nNull hyp.: the effect of x on bluecty is zero\nAlt. hyp.: the effect of x on bluecty is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.487      0.003  177.974  &lt; .001  ***\ncontrol          0.004      0.005    0.854   0.393     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.729 df(1, 49976), p.value 0.393\nNr obs: 49,978 (105 obs. dropped)\n\nSum of squares:\n\n                df      SS\nRegression       1       0\nError       49,976  12,487\nTotal       49,977  12,488\n\nRoot Mean Square Error (RMSE):\n0.5\n\n\nWe see the same t-statistic here, and the p-value is .396, which is well above the .05 threshold we would need to reject the null hypothesis.\n\n\nfreq\n\n#freq - the number of prior donations\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['freq'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['freq'].dropna()\n\n# manual t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"freq\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nManual t-statistic: -0.11084502380904246\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : freq\nExplanatory variables: control\nNull hyp.: the effect of x on freq is zero\nAlt. hyp.: the effect of x on freq is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        8.035      0.062  128.871  &lt; .001  ***\ncontrol          0.012      0.108    0.111   0.912     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.0\nF-statistic: 0.012 df(1, 50081), p.value 0.912\nNr obs: 50,083\n\nSum of squares:\n\n                df         SS\nRegression       1          1\nError       50,081  6,502,323\nTotal       50,082  6,502,325\n\nRoot Mean Square Error (RMSE):\n11.394\n\n\nThere is no significant difference between the treatment and control groups in terms of the number of prior donations. The t-statistic is very close to zero, and the p-value is well above 0.05, indicating no statistically significant difference at the 95% confidence level. This is consistent across both the t-test and linear regression.\n\n\nfemale\n\n#female - donor county is blue\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['female'].dropna()\ncontrol_group = karlan_data[karlan_data['control'] == 1]['female'].dropna()\n\n# manual t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"female\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nManual t-statistic: -1.7535132542519636\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : female\nExplanatory variables: control\nNull hyp.: the effect of x on female is zero\nAlt. hyp.: the effect of x on female is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.275      0.002  110.987  &lt; .001  ***\ncontrol          0.008      0.004    1.758   0.079    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.092 df(1, 48970), p.value 0.079\nNr obs: 48,972 (1,111 obs. dropped)\n\nSum of squares:\n\n                df     SS\nRegression       1      0\nError       48,970  9,821\nTotal       48,971  9,822\n\nRoot Mean Square Error (RMSE):\n0.448\n\n\nHere the t-statistic generated from the manual test is close to -1.96, but still less extreme at -1.75. This means we fail to reject the null hypothesis that the treatment and control groups are statistically significantly different from one another at the 95% confidence level.\nWhen we run this through a pre-built program, we find the p-value is .08, which is above the .05 threshold but below the .10 threshold.\nThe difference between the percentage of female potential donors is marginally different between the two groups, this difference is not significant at the 95% confidence level. This is true in both the t-test and the linear regression. This variable however does have a significant difference at the 90% confidence level, so it would be worth noting.\n\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\nimport matplotlib.pyplot as plt\n\ndonated_treatment = karlan_data[karlan_data['treatment'] == 1][\"gave\"].mean()\nprint(f\"{round(donated_treatment*100,2)}% of treatment group donated\")\ndonated_control = karlan_data[karlan_data['control'] == 1][\"gave\"].mean()\nprint(f\"{round(donated_control*100,2)}% of control group donated\")\n\nplt.figure(figsize=(8, 6))\nplt.bar(['Treatment', 'Control'], [donated_treatment, donated_control], color=['green', 'pink'])\nplt.title('Donation Rates by Group')\nplt.ylabel('Donation Rate')\n\n2.2% of treatment group donated\n1.79% of control group donated\n\n\nText(0, 0.5, 'Donation Rate')\n\n\n\n\n\n\n\n\n\n\n\n#groups\ntreatment_group = karlan_data[karlan_data['treatment'] == 1]['gave']\ncontrol_group = karlan_data[karlan_data['control'] == 1]['gave']\n\n# t_test\nn1, n2 = len(treatment_group), len(control_group)\nmean1, mean2 = np.mean(treatment_group), np.mean(control_group)\nvar1, var2 = np.var(treatment_group, ddof=1), np.var(control_group, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n\n\n#linear regression\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"gave\", evar=[\"control\"])\nreg.summary(rmse=True, ssq=True)\n\nManual t-statistic: 3.2094621908279835\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : gave\nExplanatory variables: control\nNull hyp.: the effect of x on gave is zero\nAlt. hyp.: the effect of x on gave is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.022      0.001   28.326  &lt; .001  ***\ncontrol         -0.004      0.001   -3.101   0.002   **\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 9.618 df(1, 50081), p.value 0.002\nNr obs: 50,083\n\nSum of squares:\n\n                df     SS\nRegression       1      0\nError       50,081  1,012\nTotal       50,082  1,012\n\nRoot Mean Square Error (RMSE):\n0.142\n\n\nThere difference between the treatment and control group’s response rate is significant at the 95% confidence level (the t-value is more extreme than 1.96 for a two-tailed test). The treatment group has a higher response rate than the control group, which suggests that the matching grant appeal is effective in increasing the likelihood of making a donation. This finding aligns with the hypothesis that matching grants can enhance donor motivation and engagement.\n\n#probit regression\nimport statsmodels.api as sm\n\nX = karlan_data['treatment']\nY = karlan_data['gave']\n\nX = sm.add_constant(X)\n\n# probit model\nprobit_model = sm.Probit(Y, X)\nresult = probit_model.fit()\n\nprint(result.summary())\n\n#marginal effects to see if results match from the study\nmfx = result.get_margeff()\nprint(mfx.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        18:03:13   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n# t-test comparing 1:1 match rate and 2:1 match rate\n\n#groups\nmatch_1_1 = karlan_data[karlan_data['ratio'] == 1]['gave']\nmatch_2_1 = karlan_data[karlan_data['ratio2'] == 1]['gave']\n\n# t_test\nn1, n2 = len(match_1_1), len(match_2_1)\nmean1, mean2 = np.mean(match_1_1), np.mean(match_2_1)\nvar1, var2 = np.var(match_1_1, ddof=1), np.var(match_2_1, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\n\nprint(\"Manual t-statistic:\", t_manual)\n# Two-tailed p-value\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\nprint(\"Manual p-value:\", p_value)\n\nManual t-statistic: -0.965048975142932\nManual p-value: 0.33452727037590346\n\n\n\n# t-test comparing 2:1 match rate and 3:1 match rate\n#groups\nmatch_2_1 = karlan_data[karlan_data['ratio2'] == 1]['gave']\nmatch_3_1 = karlan_data[karlan_data['ratio3'] == 1]['gave']\n\n# t_test\nn1, n2 = len(match_2_1), len(match_3_1)\nmean1, mean2 = np.mean(match_2_1), np.mean(match_3_1)\nvar1, var2 = np.var(match_2_1, ddof=1), np.var(match_3_1, ddof=1)\n\n# Standard error\nse = np.sqrt(var1/n1 + var2/n2)\n\n# t-stat\nt_manual = (mean1 - mean2) / se\nprint(\"Manual t-statistic:\", t_manual)\n\n# Two-tailed p-value\n\np_value = 2 * (1 - t.cdf(abs(t_manual), df))\nprint(\"Manual p-value:\", p_value)\n\nManual t-statistic: -0.05011581369764474\nManual p-value: 0.9600303977894389\n\n\nThe negative t-statistic indicates that the 2:1 match ratio has a higher mean that the 1:1 ratio, however this difference is not significant at the 95% confidence level. The p-value is .34, which is well above the .05 threshold we would need to reject the null hypothesis.\nThe same applies to the 3:1 match ratio, with a p-value of .96 and a smaller difference between the two groups.\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\n\nkarlan_data[\"ratio1\"] = (karlan_data[\"ratio\"] == 1).astype(int)\n\n\nX = karlan_data[['ratio1','ratio2','ratio3']]\nY = karlan_data['gave']\n\nX = sm.add_constant(X)\n\n# probit model\nprobit_model = sm.Probit(Y, X)\nresult = probit_model.fit()\n\nprint(result.summary())\n\n#marginal effects to see if results match from the study\nmfx = result.get_margeff()\nprint(mfx.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100430\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50079\nMethod:                           MLE   Df Model:                            3\nDate:                Tue, 22 Apr 2025   Pseudo R-squ.:                0.001108\nTime:                        18:25:42   Log-Likelihood:                -5029.8\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                   0.01091\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\nratio1         0.0616      0.036      1.726      0.084      -0.008       0.132\nratio2         0.0980      0.035      2.792      0.005       0.029       0.167\nratio3         0.0998      0.035      2.847      0.004       0.031       0.169\n==============================================================================\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0031      0.002      1.724      0.085      -0.000       0.007\nratio2         0.0049      0.002      2.786      0.005       0.001       0.008\nratio3         0.0050      0.002      2.841      0.004       0.002       0.008\n==============================================================================\n\n\n1:1 ratio shows a coefficient 0.062, meaning the 1:1 ratio is less likely to lead to a donation than the other ratio’s but a match should still increase the probability for a give. The 2:1 ratio has an odds ratio of 0.0980, meaning it is slightly more likely to lead to a donation than the control group. The 3:1 ratio has an odds ratio of 0.0998, meaning it is slightly more likely to lead to a donation than the 2:1 ratio. The p_values indicate that the results for ratio 2 and ratio 3 are statistically significant at the 95% confidence level, while the results for ratio 1 are not.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n#means\nmean_1_1 = karlan_data[karlan_data[\"ratio\"] == 1][\"gave\"].mean()\nmean_2_1 = karlan_data[karlan_data[\"ratio\"] == 2][\"gave\"].mean()\nmean_3_1 = karlan_data[karlan_data[\"ratio\"] == 3][\"gave\"].mean()\n\n#differences\ndiff_2_1_vs_1_1 = mean_2_1 - mean_1_1\ndiff_3_1_vs_2_1 = mean_3_1 - mean_2_1\n\nprint(\"2:1 vs 1:1:\", diff_2_1_vs_1_1)\nprint(\"3:1 vs 2:1:\", diff_3_1_vs_2_1)\n\n2:1 vs 1:1: 0.0018842510217149944\n3:1 vs 2:1: 0.00010002398025293902\n\n\n\ncoef_1_1 = result.params['ratio1']\ncoef_2_1 = result.params['ratio2']\ncoef_3_1 = result.params['ratio3']\n\n# Difference in effects\ndiff_2_1_vs_1_1 = coef_2_1 - coef_1_1\ndiff_3_1_vs_2_1 = coef_3_1 - coef_2_1\nprint(\"Regression-based effect of 3:1 vs 2:1 match:\", diff_3_1_vs_2_1)\nprint(\"Regression-based effect of 2:1 vs 1:1 match:\", diff_2_1_vs_1_1)\n\nmfx = result.get_margeff()\nprint(mfx.summary())\n\nRegression-based effect of 3:1 vs 2:1 match: 0.0018572014854180002\nRegression-based effect of 2:1 vs 1:1 match: 0.03634986488779221\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nratio1         0.0031      0.002      1.724      0.085      -0.000       0.007\nratio2         0.0049      0.002      2.786      0.005       0.001       0.008\nratio3         0.0050      0.002      2.841      0.004       0.002       0.008\n==============================================================================\n\n\nBoth raw and model-based results suggest that increasing the match ratio from 1:1 to 2:1 significantly improves donation rates. However, increasing it further to 3:1 provides almost no additional benefit. These findings support the paper’s interpretation that higher match ratios can increase giving, but they also highlight diminishing returns at higher match levels.\nThe p-values for ratio1 are significant at the 90% level but the results for ratio2 and ratio3 are significant at the 95% level. .\nBased on the probit model, the 3:1 match leads to a slightly higher (0.0018) latent index score for donation compared to the 2:1 match, holding everything else constant.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\nreg = rsm.model.regress({\"karlan\": karlan_data}, rvar=\"amount\", evar=[\"treatment\"])\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept        0.813      0.067   12.063  &lt; .001  ***\ntreatment        0.154      0.083    1.861   0.063    .\n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: 0.0\nF-statistic: 3.461 df(1, 50081), p.value 0.063\nNr obs: 50,083\n\n\nWe learn that treatment effect has a slightly significant (and small) effect on size of donation\n\nkarlan_donations = karlan_data[karlan_data['gave'] ==1 ]\nreg = rsm.model.regress({\"karlan\": karlan_donations}, rvar=\"amount\", evar=[\"treatment\"])\nreg.summary()\n\nLinear regression (OLS)\nData                 : karlan\nResponse variable    : amount\nExplanatory variables: treatment\nNull hyp.: the effect of x on amount is zero\nAlt. hyp.: the effect of x on amount is not zero\n\n           coefficient  std.error  t.value p.value     \nIntercept       45.540      2.423   18.792  &lt; .001  ***\ntreatment       -1.668      2.872   -0.581   0.561     \n\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-squared: 0.0, Adjusted R-squared: -0.001\nF-statistic: 0.337 df(1, 1032), p.value 0.561\nNr obs: 1,034\n\n\nWhen only including donors, the coefficient of the regression shows us the treatment group donates about $1.67 less than the control group, however this result is not significant at the 95% confidence level. This does not have a causal interpretation because treatment may affect the likelihood of donating, and here we’re looking at the size of the donation conditional on donating.\n\ndonors = karlan_data[karlan_data['gave'] ==1]\n\n# Control\ncontrol_donors = donors[donors['treatment'] == 0]['amount']\nplt.hist(control_donors, bins=30, alpha=0.7, label='Control')\nplt.axvline(control_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title(\"Control Group: Donation Amounts\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\nplt.show()\n\n# Treatment\ntreated_donors = donors[donors['treatment'] == 1]['amount']\nplt.hist(treated_donors, bins=30, alpha=0.7, label='Treatment')\nplt.axvline(treated_donors.mean(), color='red', linestyle='dashed', linewidth=2)\nplt.title(\"Treatment Group: Donation Amounts\")\nplt.xlabel(\"Donation Amount\")\nplt.ylabel(\"Frequency\")\nplt.legend()\nplt.show()"
  },
  {
    "objectID": "blog/project1/Assignment 1 - AB Testing Code.html#simulation-experiment",
    "href": "blog/project1/Assignment 1 - AB Testing Code.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n#Simulated Numbers\nnp.random.seed(1)  # For reproducibilit\nsim_control = np.random.choice(control_donors, size=10000, replace=True)\nsim_treated = np.random.choice(treated_donors, size=10000, replace=True)\ndiff=sim_treated-sim_control\n\n#Cumulative Average\ncumulative_avg = np.cumsum(diff) / np.arange(1, len(diff) + 1)\n\n#True Difference in means\nTrue_Diff = treated_donors.mean() - control_donors.mean()\n\nplt.plot(cumulative_avg, label='Cumulative Average')\nplt.axhline(True_Diff, color='red', linestyle='dashed', linewidth=2, label='True Difference')\nplt.title('Cumulative Average of Differences')\nplt.xlabel('Number of Samples')\nplt.ylabel('Cumulative Average')\nplt.legend()\n\n\n-1.6683922\n\n\n\n\n\n\n\n\n\nThe cumulative average does approach the true difference in means. As we increase the number of samples, the variation stabilizes. The cumulative average converges to the true difference in means. This demonstrates the Law of Large Numbers, as the sample mean approaches the population mean as the sample size increases.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”\n\np_control = 0.018\np_treatment = 0.022\n\n# parameters\nsample_sizes = [50, 200, 500, 1000]\nn_simulations = 1000\ntrue_diff = p_treatment - p_control\n\nfig, axs = plt.subplots(2, 2, figsize=(12, 8))\naxs = axs.flatten()\n\n# Simulate and plot \nfor i, n in enumerate(sample_sizes):\n    avg_diffs = []\n\n    for _ in range(n_simulations):\n        control_sample = np.random.binomial(1, p_control, n)\n        treatment_sample = np.random.binomial(1, p_treatment, n)\n        avg_diff = np.mean(treatment_sample) - np.mean(control_sample)\n        avg_diffs.append(avg_diff)\n\n    axs[i].hist(avg_diffs, bins=30, alpha=0.7, color=\"skyblue\", edgecolor=\"black\")\n    axs[i].axvline(x=true_diff, color='red', linestyle='--', label='True Difference (0.004)')\n    axs[i].axvline(x=0, color='black', linestyle=':', label='Zero')\n    axs[i].set_title(f\"Sample Size = {n}\")\n    axs[i].set_xlabel(\"Avg Treatment - Control\")\n    axs[i].set_ylabel(\"Frequency\")\n    axs[i].legend()\n\n# Main title and layout\nplt.suptitle(\"CLT: Distribution of Average Differences by Sample Size\", fontsize=14)\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\n\nThe four histograms above illustrate how the distribution of average differences in donation rates between treatment and control groups evolves as sample size increases. This simulation confirms the Central Limit Theorem (CLT).\nAt n = 50, the distribution is wide and relatively flat, and zero lies close to the center. This shows that with small sample sizes, we often can’t distinguish signal from noise, and random variation makes the estimated treatment effect unreliable.\nAt n = 200, the distribution becomes more symmetric and bell-shaped. The true treatment effect (0.004) begins to emerge, though zero is still within the central bulk of the distribution, indicating moderate uncertainty.\nAt n = 500, the distribution tightens further, and the center of the histogram clearly shifts to the right of zero. Zero now lies toward the edge (tail) of the distribution, which suggests that the true effect is increasingly distinguishable from no effect.\nAt n = 1000, the distribution is even narrower and sharply centered near 0.004. Zero is clearly in the tail, meaning that under this sample size, the true effect is more evident.\nConclusion: As sample size increases, the sampling distribution of the average difference becomes more normal and less variable, with its mean converging to the true treatment effect. Zero moves from the center to the tails of the distribution, reinforcing that larger samples improve the precision of effect estimates and the reliability of hypothesis testing."
  },
  {
    "objectID": "blog/project1/hw1_questions.html",
    "href": "blog/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#introduction",
    "href": "blog/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#data",
    "href": "blog/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#experimental-results",
    "href": "blog/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "blog/project1/hw1_questions.html#simulation-experiment",
    "href": "blog/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  },
  {
    "objectID": "resume/hw1_questions.html",
    "href": "resume/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "resume/hw1_questions.html#introduction",
    "href": "resume/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nto do: expand on the description of the experiment.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "resume/hw1_questions.html#data",
    "href": "resume/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper)."
  },
  {
    "objectID": "resume/hw1_questions.html#experimental-results",
    "href": "resume/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot."
  },
  {
    "objectID": "resume/hw1_questions.html#simulation-experiment",
    "href": "resume/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nto do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 100,00 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.”"
  }
]